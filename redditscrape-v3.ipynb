{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75d0ccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from psaw import PushshiftAPI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293afa13",
   "metadata": {},
   "source": [
    "## API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8d98773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmaw import PushshiftAPI\n",
    "api = PushshiftAPI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a57882",
   "metadata": {},
   "source": [
    "## Select subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "383cfdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 5 comments from Pushshift\n"
     ]
    }
   ],
   "source": [
    "subreddit=\"climate\"\n",
    "limit=1000\n",
    "\n",
    "# adding timeframe \n",
    "before = int(dt.datetime(2022,1,1,1,0).timestamp())\n",
    "after = int(dt.datetime(2022,1,1,0,0).timestamp())\n",
    "\n",
    "comments = api.search_comments(subreddit=subreddit, limit=limit, before=before, after=after)\n",
    "print(f'Retrieved {len(comments)} comments from Pushshift')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bca79bf",
   "metadata": {},
   "source": [
    "## Start scraping\n",
    "Scraping the above selected subreddit for every day. Then saving it in a csv for per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c831ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "more than 1000 comments in year 2022\n",
      "more than 1000 comments in month 1 - 2022\n",
      "datebefore 2 - 1 -  2022 date after 1 - 1 -  2022\n",
      "Retrieved 224 comments per day from Pushshift\n",
      "datebefore 3 - 1 -  2022 date after 2 - 1 -  2022\n",
      "Retrieved 131 comments per day from Pushshift\n",
      "datebefore 4 - 1 -  2022 date after 3 - 1 -  2022\n",
      "Retrieved 317 comments per day from Pushshift\n",
      "datebefore 5 - 1 -  2022 date after 4 - 1 -  2022\n",
      "Retrieved 270 comments per day from Pushshift\n",
      "datebefore 6 - 1 -  2022 date after 5 - 1 -  2022\n",
      "Retrieved 128 comments per day from Pushshift\n",
      "datebefore 7 - 1 -  2022 date after 6 - 1 -  2022\n",
      "Retrieved 273 comments per day from Pushshift\n",
      "datebefore 8 - 1 -  2022 date after 7 - 1 -  2022\n",
      "Retrieved 245 comments per day from Pushshift\n",
      "datebefore 9 - 1 -  2022 date after 8 - 1 -  2022\n",
      "Retrieved 269 comments per day from Pushshift\n",
      "datebefore 10 - 1 -  2022 date after 9 - 1 -  2022\n",
      "Retrieved 229 comments per day from Pushshift\n",
      "datebefore 11 - 1 -  2022 date after 10 - 1 -  2022\n",
      "Retrieved 198 comments per day from Pushshift\n",
      "datebefore 12 - 1 -  2022 date after 11 - 1 -  2022\n",
      "Retrieved 261 comments per day from Pushshift\n",
      "datebefore 13 - 1 -  2022 date after 12 - 1 -  2022\n",
      "Retrieved 290 comments per day from Pushshift\n",
      "datebefore 14 - 1 -  2022 date after 13 - 1 -  2022\n",
      "Retrieved 288 comments per day from Pushshift\n",
      "datebefore 15 - 1 -  2022 date after 14 - 1 -  2022\n",
      "Retrieved 304 comments per day from Pushshift\n",
      "datebefore 16 - 1 -  2022 date after 15 - 1 -  2022\n",
      "Retrieved 150 comments per day from Pushshift\n",
      "datebefore 17 - 1 -  2022 date after 16 - 1 -  2022\n",
      "Retrieved 225 comments per day from Pushshift\n",
      "datebefore 18 - 1 -  2022 date after 17 - 1 -  2022\n",
      "Retrieved 144 comments per day from Pushshift\n",
      "datebefore 19 - 1 -  2022 date after 18 - 1 -  2022\n",
      "Retrieved 533 comments per day from Pushshift\n",
      "datebefore 20 - 1 -  2022 date after 19 - 1 -  2022\n",
      "Retrieved 341 comments per day from Pushshift\n",
      "datebefore 21 - 1 -  2022 date after 20 - 1 -  2022\n",
      "Retrieved 150 comments per day from Pushshift\n",
      "datebefore 22 - 1 -  2022 date after 21 - 1 -  2022\n",
      "Retrieved 189 comments per day from Pushshift\n",
      "datebefore 23 - 1 -  2022 date after 22 - 1 -  2022\n",
      "Retrieved 226 comments per day from Pushshift\n",
      "datebefore 24 - 1 -  2022 date after 23 - 1 -  2022\n",
      "Retrieved 255 comments per day from Pushshift\n",
      "datebefore 25 - 1 -  2022 date after 24 - 1 -  2022\n",
      "Retrieved 180 comments per day from Pushshift\n",
      "datebefore 26 - 1 -  2022 date after 25 - 1 -  2022\n",
      "Retrieved 178 comments per day from Pushshift\n",
      "datebefore 27 - 1 -  2022 date after 26 - 1 -  2022\n",
      "Retrieved 375 comments per day from Pushshift\n",
      "datebefore 28 - 1 -  2022 date after 27 - 1 -  2022\n",
      "Retrieved 239 comments per day from Pushshift\n",
      "datebefore 29 - 1 -  2022 date after 28 - 1 -  2022\n",
      "Retrieved 229 comments per day from Pushshift\n",
      "datebefore 30 - 1 -  2022 date after 29 - 1 -  2022\n",
      "Retrieved 165 comments per day from Pushshift\n",
      "datebefore 31 - 1 -  2022 date after 30 - 1 -  2022\n",
      "Retrieved 234 comments per day from Pushshift\n",
      "more than 1000 comments in year 2022\n",
      "more than 1000 comments in month 2 - 2022\n",
      "datebefore 1 - 2 -  2022 date after 31 - 1 -  2022\n",
      "Retrieved 122 comments per day from Pushshift\n",
      "datebefore 2 - 2 -  2022 date after 1 - 2 -  2022\n",
      "Retrieved 118 comments per day from Pushshift\n",
      "datebefore 3 - 2 -  2022 date after 2 - 2 -  2022\n",
      "Retrieved 128 comments per day from Pushshift\n",
      "datebefore 4 - 2 -  2022 date after 3 - 2 -  2022\n",
      "Retrieved 328 comments per day from Pushshift\n",
      "datebefore 5 - 2 -  2022 date after 4 - 2 -  2022\n",
      "Retrieved 97 comments per day from Pushshift\n",
      "datebefore 6 - 2 -  2022 date after 5 - 2 -  2022\n",
      "Retrieved 168 comments per day from Pushshift\n",
      "datebefore 7 - 2 -  2022 date after 6 - 2 -  2022\n",
      "Retrieved 141 comments per day from Pushshift\n",
      "datebefore 8 - 2 -  2022 date after 7 - 2 -  2022\n",
      "Retrieved 72 comments per day from Pushshift\n",
      "datebefore 9 - 2 -  2022 date after 8 - 2 -  2022\n",
      "Retrieved 306 comments per day from Pushshift\n",
      "datebefore 10 - 2 -  2022 date after 9 - 2 -  2022\n",
      "Retrieved 205 comments per day from Pushshift\n",
      "datebefore 11 - 2 -  2022 date after 10 - 2 -  2022\n",
      "Retrieved 172 comments per day from Pushshift\n",
      "datebefore 12 - 2 -  2022 date after 11 - 2 -  2022\n",
      "Retrieved 207 comments per day from Pushshift\n",
      "datebefore 13 - 2 -  2022 date after 12 - 2 -  2022\n",
      "Retrieved 362 comments per day from Pushshift\n",
      "datebefore 14 - 2 -  2022 date after 13 - 2 -  2022\n",
      "Retrieved 121 comments per day from Pushshift\n",
      "datebefore 15 - 2 -  2022 date after 14 - 2 -  2022\n",
      "Retrieved 101 comments per day from Pushshift\n",
      "datebefore 16 - 2 -  2022 date after 15 - 2 -  2022\n",
      "Retrieved 279 comments per day from Pushshift\n",
      "datebefore 17 - 2 -  2022 date after 16 - 2 -  2022\n",
      "Retrieved 162 comments per day from Pushshift\n",
      "datebefore 18 - 2 -  2022 date after 17 - 2 -  2022\n",
      "Retrieved 156 comments per day from Pushshift\n",
      "datebefore 19 - 2 -  2022 date after 18 - 2 -  2022\n",
      "Retrieved 206 comments per day from Pushshift\n",
      "datebefore 20 - 2 -  2022 date after 19 - 2 -  2022\n",
      "Retrieved 170 comments per day from Pushshift\n",
      "datebefore 21 - 2 -  2022 date after 20 - 2 -  2022\n",
      "Retrieved 123 comments per day from Pushshift\n",
      "datebefore 22 - 2 -  2022 date after 21 - 2 -  2022\n",
      "Retrieved 87 comments per day from Pushshift\n",
      "datebefore 23 - 2 -  2022 date after 22 - 2 -  2022\n",
      "Retrieved 114 comments per day from Pushshift\n",
      "datebefore 24 - 2 -  2022 date after 23 - 2 -  2022\n",
      "Retrieved 138 comments per day from Pushshift\n",
      "datebefore 25 - 2 -  2022 date after 24 - 2 -  2022\n",
      "Retrieved 75 comments per day from Pushshift\n",
      "datebefore 26 - 2 -  2022 date after 25 - 2 -  2022\n",
      "Retrieved 98 comments per day from Pushshift\n",
      "datebefore 27 - 2 -  2022 date after 26 - 2 -  2022\n",
      "Retrieved 102 comments per day from Pushshift\n",
      "datebefore 28 - 2 -  2022 date after 27 - 2 -  2022\n",
      "Retrieved 104 comments per day from Pushshift\n",
      "more than 1000 comments in year 2022\n",
      "more than 1000 comments in month 3 - 2022\n",
      "datebefore 1 - 3 -  2022 date after 28 - 2 -  2022\n",
      "Retrieved 159 comments per day from Pushshift\n",
      "datebefore 2 - 3 -  2022 date after 1 - 3 -  2022\n",
      "Retrieved 282 comments per day from Pushshift\n",
      "datebefore 3 - 3 -  2022 date after 2 - 3 -  2022\n",
      "Retrieved 105 comments per day from Pushshift\n",
      "datebefore 4 - 3 -  2022 date after 3 - 3 -  2022\n",
      "Retrieved 70 comments per day from Pushshift\n",
      "datebefore 5 - 3 -  2022 date after 4 - 3 -  2022\n",
      "Retrieved 107 comments per day from Pushshift\n",
      "datebefore 6 - 3 -  2022 date after 5 - 3 -  2022\n",
      "Retrieved 55 comments per day from Pushshift\n",
      "datebefore 7 - 3 -  2022 date after 6 - 3 -  2022\n",
      "Retrieved 112 comments per day from Pushshift\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "temp_df = pd.DataFrame() #Temporary empty dataframe\n",
    "\n",
    "for m in range(1, 13):\n",
    "    year = 2022\n",
    "    yearAfter = year\n",
    "    monthBefore = m\n",
    "    monthAfter = m\n",
    "    day = 32\n",
    "    minutes = 0\n",
    "    \n",
    "    # YEARLY SCRAPE\n",
    "    # If year has comments < 1000 scrape everything at once \n",
    "    scrapeYearDateBefore = int(dt.datetime(year,12,31,0,0).timestamp())\n",
    "    scrapeYearDateAfter = int(dt.datetime(year,1,1,0,0).timestamp())\n",
    "       \n",
    "    # Scrape all comments per Year\n",
    "    commentsYear = api.search_comments(subreddit=subreddit, limit=limit, before=scrapeYearDateBefore, after=scrapeYearDateAfter)\n",
    "    \n",
    "    \n",
    "    if (len(commentsYear) < 1000): \n",
    "        print(f'Retrieved {len(commentsYear)} comments in {year} from Pushshift')\n",
    "        # convert comments into a datafrom\n",
    "        comments_df = pd.DataFrame(commentsYear)\n",
    "\n",
    "        #add all datapoints to a temporary dataframe\n",
    "        temp_df = temp_df.append(comments_df, ignore_index=True)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # MONTLY SCRAPE\n",
    "    else:\n",
    "        print(f'more than {len(commentsYear)} comments in year {year}')\n",
    "        endMonthDate = 31\n",
    "        \n",
    "        if(m == 1) or (m == 3) or (m == 5) or (m == 7) or (m == 8) or (m == 10) or (m == 12):\n",
    "            endMonthDate = 31\n",
    "        elif(m == 2):\n",
    "            endMonthDate = 28\n",
    "        else: \n",
    "            endMonthDate = 30\n",
    "            \n",
    "        # If month has comments < 1000 scrape all monthly data at once \n",
    "        scrapeMonthDateBefore = int(dt.datetime(year,m,endMonthDate,0,0).timestamp())\n",
    "        scrapeMonthDateAfter = int(dt.datetime(year,m,1,0,0).timestamp())\n",
    "        \n",
    "        # Scrape all comments per day\n",
    "        commentsMonth = api.search_comments(subreddit=subreddit, limit=limit, before=scrapeMonthDateBefore, after=scrapeMonthDateAfter)\n",
    "        \n",
    "        if (len(commentsMonth) < 1000): \n",
    "            print(f'Retrieved {len(commentsMonth)} comments in month: {m} - from Pushshift')\n",
    "            # convert comments into a datafrom\n",
    "            comments_df = pd.DataFrame(commentsMonth)\n",
    "\n",
    "            #add all datapoints to a temporary dataframe\n",
    "            temp_df = temp_df.append(comments_df, ignore_index=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "        # DAILY SCRAPE\n",
    "        else:\n",
    "            print(f'more than {len(commentsMonth)} comments in month {m} - {year}')\n",
    "            if (m == 2): #februari \n",
    "                day = 29\n",
    "            if (m == 4) or (m == 6) or (m == 9) or (m == 11): # months with 30 days -> its days +1 for the loop\n",
    "                day = 31\n",
    "\n",
    "            for d in range(1, day):\n",
    "                # date variables\n",
    "                dayBefore = d\n",
    "                dayAfter = d-1\n",
    "\n",
    "                # change dayAfter / monthAfter on certain conditions\n",
    "                if(dayAfter == 0): # \n",
    "                    monthAfter = m-1\n",
    "                    if(m == 2):\n",
    "                        dayAfter = 31\n",
    "                    elif(m==3):\n",
    "                        dayAfter = 28\n",
    "                    elif (m == 4) or (m == 6) or (m == 9) or (m == 11) or (m == 13):\n",
    "                        dayAfter = 31\n",
    "                    else: dayAfter = 30\n",
    "                else: monthAfter = m\n",
    "\n",
    "                if(monthAfter == 0):\n",
    "                    continue\n",
    "\n",
    "                #set time frame for scraping -> Scraping for every day in the year.\n",
    "                scrapeDayDateBefore = int(dt.datetime(year,monthBefore,dayBefore,0,0).timestamp())\n",
    "                scrapeDayDateAfter = int(dt.datetime(yearAfter,monthAfter,dayAfter,0,0).timestamp())\n",
    "\n",
    "\n",
    "                # Scrape all comments per day\n",
    "                commentsDay = api.search_comments(subreddit=subreddit, limit=limit, before=scrapeDayDateBefore, after=scrapeDayDateAfter)\n",
    "                  \n",
    "                # if statement day comments < 1000\n",
    "                if (len(commentsDay) < 1000): \n",
    "                    print('datebefore', dayBefore, '-', monthBefore, '- ', year, 'date after', dayAfter, '-', monthAfter, '- ', yearAfter)\n",
    "                    print(f'Retrieved {len(commentsDay)} comments per day from Pushshift')\n",
    "                    # convert comments into a datafrom\n",
    "                    comments_df = pd.DataFrame(commentsDay)\n",
    "\n",
    "                    #add all datapoints to a temporary dataframe\n",
    "                    temp_df = temp_df.append(comments_df, ignore_index=True)\n",
    "      \n",
    "    \n",
    "    \n",
    "    \n",
    "                # HOURLY SCRAPE\n",
    "                else: \n",
    "                    print(f'more than {len(commentsDay)} comments on day {dayAfter}-{monthAfter}-{yearAfter} -- {dayBefore}-{monthBefore}-{year}')\n",
    "\n",
    "                    for h in range(24):\n",
    "\n",
    "                        # add an hour to the datetime object\n",
    "                        hourBefore = h + 1\n",
    "                        hourAfter = h\n",
    "                        minuteAfter = 0\n",
    "\n",
    "                        if (hourBefore == 24):\n",
    "                            hourBefore = 23\n",
    "                            minutes = 59\n",
    "                        else: \n",
    "                            hourBefore = h + 1\n",
    "                            minutes = 0\n",
    "                            \n",
    "\n",
    "\n",
    "                        #set time frame for scraping -> Scraping for every hour in the day\n",
    "                        scrapeHourDateBefore = int(dt.datetime(year,monthBefore,d,hourBefore,minutes).timestamp())\n",
    "                        scrapeHourDateAfter = int(dt.datetime(yearAfter,monthAfter,d,hourAfter,minuteAfter).timestamp())      \n",
    "                        \n",
    "                        # Scrape all comments per hour\n",
    "                        commentsHour = api.search_comments(subreddit=subreddit, limit=limit, before=scrapeHourDateBefore, after=scrapeHourDateAfter)\n",
    "                        \n",
    "                        # if statement hour comments < 1000\n",
    "                        if (len(commentsHour) < 1000): \n",
    "                            print('datebefore', dt.datetime(year,monthBefore,d,hourBefore,minutes), 'date after', dt.datetime(yearAfter,monthAfter,d,hourAfter,minuteAfter)) \n",
    "                            print(f'Retrieved {len(commentsHour)} comments per hour from Pushshift')\n",
    "                            # convert comments into a datafrom\n",
    "                            comments_df = pd.DataFrame(commentsHour)\n",
    "\n",
    "                            #add all datapoints to a temporary dataframe\n",
    "                            temp_df = temp_df.append(comments_df, ignore_index=True)\n",
    "\n",
    "                        # HOURLY SCRAPE\n",
    "                        else:\n",
    "                            # convert comments into a datafrom\n",
    "                            comments_df = pd.DataFrame(commentsHour)\n",
    "\n",
    "                            #add all datapoints to a temporary dataframe\n",
    "                            temp_df = temp_df.append(comments_df, ignore_index=True)\n",
    "                            print('ERROR MORE THAN 1000, however, still going on. INCOMPLETE')\n",
    "                            print(f'more than {len(commentsHour)} comments on day {d}-{m}-{year} between',  dt.datetime(year,monthBefore,d,hourBefore,minutes), '-', dt.datetime(yearAfter,monthAfter,d,hourAfter,minuteAfter))\n",
    "#                             raise ValueError(\"More than 1000 comments in this HOUR.\")\n",
    "\n",
    "                                \n",
    "                                \n",
    "                                \n",
    "                                \n",
    "                                \n",
    "\n",
    "# all datapoints in temporary dataframe to one dataframe\n",
    "df1 = pd.DataFrame(temp_df)\n",
    "                                      \n",
    "# create the filename with the variable name embedded\n",
    "filename = f'{subreddit}_{year}.csv'\n",
    "\n",
    "# save the dataframe to the file with the embedded variable name\n",
    "df1.to_csv(filename, encoding='utf-8', header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa78698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a654cb8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
